p8105_hw5_jt3649
================
Juan Tang
2025-11-12

### Problem 1

``` r
set.seed(1)
birthday_sim = function(n_people){
  birthdays = sample(1:365, size = n_people, replace = TRUE) #draw n_people birthdays, each between 1 and 365
  any(duplicated(birthdays)) # return true if any birthday appears more than once
}
```

``` r
n_sims = 10000 # number of simulations
birthday_results = 
  tibble(n = 2:50) |>
  mutate(
    # for each n, do 10000 independent simulations
    sim_results = map(
      n, 
      ~ replicate(n_sims, birthday_sim(.x))
    )
  ) |>
  # turn the logical vectors into long format
  unnest_longer(sim_results, values_to = "shared_birthday") |>
  group_by(n) |>
  summarize(
    prob_shared = mean(shared_birthday), # "TRUE" = 1, "FALSE" = 0"
    .groups = "drop"
  )
head(birthday_results)
```

    ## # A tibble: 6 Ã— 2
    ##       n prob_shared
    ##   <int>       <dbl>
    ## 1     2      0.0024
    ## 2     3      0.0085
    ## 3     4      0.0167
    ## 4     5      0.0267
    ## 5     6      0.0399
    ## 6     7      0.0521

``` r
birthday_results |>
  ggplot(aes(x = n, y = prob_shared)) + 
  geom_line() + 
  geom_point() + 
  labs(
    x = "Group size(n)", 
    y = "Probability of at least two share a brithday", 
    title = "Probabilty of shared birthday vs group size"
  )
```

![](p8105_hw5_jt3649_files/figure-gfm/birthday_plot-1.png)<!-- -->

#### Comment

- When the group sizes are small, the probability of two shared the same
  birthday is close to 0.

- The probability increases as n increases, and is above 0.5 when n is
  approx. 23.

- For relatively larger groups (close to 50), the probability of shared
  birthday approaches 1, indicating it is extremely likely that at least
  two people share a birthday.

### Problem 2

#### Simulation result

``` r
set.seed(12345)
# function that runs simulations for a given true mean "mu_true"

n = 30
sigma = 5
mu_true = 0
mu_values = 0:6
n_sims = 5000

sim_results = expand_grid(
  mu = mu_values, 
  sim = 1:5000
) |>
  mutate(
    # for each row (mu, sim) generate data from N(mu, sigma)
    x = map(mu, ~rnorm(n = n, mean = .x, sd = sigma)), 
    # one sample t-test of H0: mu = 0
    t_out = map(x, ~t.test(.x, mu = 0)), 
    # tidy the output
    t_tidy = map(t_out, broom::tidy)
  ) |>
  unnest(t_tidy) |>
  select(mu, sim, estimate, p.value)
```

#### Power result

``` r
power_results = 
  sim_results |>
  group_by(mu) |> # group all 5000 simulations by the true mu
  summarise(
    power = mean(p.value < 0.05), # compute the proportion of p-values that are < 0.05
    .groups = "drop" 
  )

power_results
```

    ## # A tibble: 7 Ã— 2
    ##      mu  power
    ##   <int>  <dbl>
    ## 1     0 0.0468
    ## 2     1 0.183 
    ## 3     2 0.539 
    ## 4     3 0.879 
    ## 5     4 0.988 
    ## 6     5 1     
    ## 7     6 1

``` r
ggplot(power_results, aes(x = mu, y = power)) +
  geom_line() + # connect points with line
  geom_point() +
  labs(
    x = "True mean (mu)",
    y = "Estimated power",
    title = "Power of One Sample t-test vs True Mean (mu)"
  ) +
  ylim(0, 1) # range, power is between 0 and 1
```

![](p8105_hw5_jt3649_files/figure-gfm/power_vs_mu_plot-1.png)<!-- -->

#### mu-hat Result

``` r
mu_hat_results =
  sim_results |>
  group_by(mu) |> # group by true mean
  summarize(
    avg_estimate_all = mean(estimate), # calculate the avg sample mean across all simulations
    avg_estimate_reject = mean(estimate[p.value < 0.05]), # calculate the avg sample mean only when H0 rejected (ie. p<0.05)
    .groups = "drop"
  )

mu_hat_long = # convert to long format
  mu_hat_results |>
  pivot_longer(
    cols = c(avg_estimate_all, avg_estimate_reject),
    names_to = "estimate_type",
    values_to = "mean_estimate"
  ) |>
  mutate(
    estimate_type = case_when(
      estimate_type == "avg_estimate_all" ~ "All samples", 
      estimate_type == "avg_estimate_reject" ~ "Only rejected"
    )
  )
```

#### Average estimate of mu-hat vs true mu plot

``` r
ggplot(
  mu_hat_long, 
       aes(x = mu, 
           y = mean_estimate, 
           color = estimate_type)
  ) +
  geom_line() +
  geom_point() +
  labs(
    x = "True mean (mu)",
    y = "Average estimate (mu-hat)",
    color = "Estimate Type",
    title = "Average Estimate of mu-hat vs true mu"
  )
```

![](p8105_hw5_jt3649_files/figure-gfm/mu-hat_vs_true_mu_plot-1.png)<!-- -->

``` r
mu_hat_results
```

    ## # A tibble: 7 Ã— 3
    ##      mu avg_estimate_all avg_estimate_reject
    ##   <int>            <dbl>               <dbl>
    ## 1     0          0.00590               0.214
    ## 2     1          1.01                  2.27 
    ## 3     2          1.98                  2.63 
    ## 4     3          2.99                  3.20 
    ## 5     4          4.00                  4.02 
    ## 6     5          5.02                  5.02 
    ## 7     6          6.01                  6.01

Is the sample average of ðœ‡Ì‚ across tests for which the null is rejected
approximately equal to the true value of ðœ‡? Why or why not?

### Problem 3

``` r
homicides_raw = 
  read_csv("homicide-data.csv")
```

    ## Rows: 52179 Columns: 12
    ## â”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ## Delimiter: ","
    ## chr (9): uid, victim_last, victim_first, victim_race, victim_age, victim_sex...
    ## dbl (3): reported_date, lat, lon
    ## 
    ## â„¹ Use `spec()` to retrieve the full column specification for this data.
    ## â„¹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

#### Description of dataset

The raw dataset contains one row per homicide case. There are 52179
observations, and 12 variables.

Important variables include: - `uid`: case ID - `reported_date`: date
the homicide was reported - `city`, `state`: location of the homicide -
`victim_last`,`victim_first`, `victim_race`, `victim_age`, `victim_sex`:
demographic information of the victim - `disposition`: case status

#### Homicides by city_state

``` r
homicides_city = 
  homicides_raw |>
  # create city_state variable
  mutate(
    city_state = str_c(city, ",", state), 
    # indicator for unsolved cases ("closed without arrest" or "open/no arrest")
    unsolved = if_else(
      disposition %in% c("Closed without arrest", "Open/No arrest"), 
      1, # unsolved
      0, # solved
    )
  ) |>
  group_by(city_state) |>
  summarize(
    n_homicides = n(), # total number of homicides in city
    n_unsolved = sum(unsolved), # number of unsolved homicides
  )

homicides_city
```

    ## # A tibble: 51 Ã— 3
    ##    city_state     n_homicides n_unsolved
    ##    <chr>                <int>      <dbl>
    ##  1 Albuquerque,NM         378        146
    ##  2 Atlanta,GA             973        373
    ##  3 Baltimore,MD          2827       1825
    ##  4 Baton Rouge,LA         424        196
    ##  5 Birmingham,AL          800        347
    ##  6 Boston,MA              614        310
    ##  7 Buffalo,NY             521        319
    ##  8 Charlotte,NC           687        206
    ##  9 Chicago,IL            5535       4073
    ## 10 Cincinnati,OH          694        309
    ## # â„¹ 41 more rows

#### Unsolved homicides in Baltimore, MD

``` r
baltimore = homicides_city |>
  filter(city_state == "Baltimore,MD")
baltimore
```

    ## # A tibble: 1 Ã— 3
    ##   city_state   n_homicides n_unsolved
    ##   <chr>              <int>      <dbl>
    ## 1 Baltimore,MD        2827       1825

``` r
# run prop.test for Baltimore
baltimore_prop = 
  prop.test(
    x = baltimore$n_unsolved, # number of unsolved cases
    n = baltimore$n_homicides # total number of cases
  )

# tidy the output
baltimore_tidy = 
  baltimore_prop |>
  broom::tidy()

# extract estimated prop. and CI
baltimore_estimate = 
  baltimore_tidy |>
  select(estimate, conf.low, conf.high)

baltimore_estimate
```

    ## # A tibble: 1 Ã— 3
    ##   estimate conf.low conf.high
    ##      <dbl>    <dbl>     <dbl>
    ## 1    0.646    0.628     0.663

The estimated proportion of homicides that are unsolved in Baltimore,MD
is 0.6455607.

The 95% confidence interval is (0.6275625, 0.6631599)

#### Proportion of unsolved homicides in all cities

``` r
city_prop_results = 
  homicides_city |>
  mutate(
    # list col of prop.test objects
    prop_test = map2(
      n_unsolved, 
      n_homicides, 
      ~ prop.test(x = .x, n = .y)
    ), 
    # list col of tidy data frames
    prop_tidy = map(prop_test, broom::tidy)
  ) |>
  unnest(prop_tidy) |>
  select(
    city_state, 
    n_homicides, 
    n_unsolved, 
    estimate, 
    conf.low, 
    conf.high
  )
```

    ## Warning: There was 1 warning in `mutate()`.
    ## â„¹ In argument: `prop_test = map2(n_unsolved, n_homicides, ~prop.test(x = .x, n
    ##   = .y))`.
    ## Caused by warning in `prop.test()`:
    ## ! Chi-squared approximation may be incorrect

``` r
city_prop_results
```

    ## # A tibble: 51 Ã— 6
    ##    city_state     n_homicides n_unsolved estimate conf.low conf.high
    ##    <chr>                <int>      <dbl>    <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque,NM         378        146    0.386    0.337     0.438
    ##  2 Atlanta,GA             973        373    0.383    0.353     0.415
    ##  3 Baltimore,MD          2827       1825    0.646    0.628     0.663
    ##  4 Baton Rouge,LA         424        196    0.462    0.414     0.511
    ##  5 Birmingham,AL          800        347    0.434    0.399     0.469
    ##  6 Boston,MA              614        310    0.505    0.465     0.545
    ##  7 Buffalo,NY             521        319    0.612    0.569     0.654
    ##  8 Charlotte,NC           687        206    0.300    0.266     0.336
    ##  9 Chicago,IL            5535       4073    0.736    0.724     0.747
    ## 10 Cincinnati,OH          694        309    0.445    0.408     0.483
    ## # â„¹ 41 more rows

#### Proportion of unsolved homicides plot

``` r
city_prop_results |>
  # organize cities according to the proportion of unsolved homicides
  mutate(
    city_state = fct_reorder(city_state, estimate)
  ) |>
  ggplot(
    aes(x = estimate, 
        y = city_state)
    ) + 
      geom_point() + 
      # add errorbar based on 95% CI
      geom_errorbar(
        aes(xmin = conf.low, 
            xmax = conf.high), 
        width = 0
    )+ 
      labs(
        title = "Estimated Proportion of Unsolved Homicides by City", 
        x = "Estimated proportion unsolved (95% CI)", 
        y = "City"
      ) 
```

![](p8105_hw5_jt3649_files/figure-gfm/prop.%20plot%20by%20city-1.png)<!-- -->
