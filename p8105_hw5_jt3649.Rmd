---
title: "p8105_hw5_jt3649"
author: "Juan Tang"
date: "2025-11-12"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(purrr)
library(ggplot2)
```

### Problem 1
```{r shared_birthday}
set.seed(1)
birthday_sim = function(n_people){
  birthdays = sample(1:365, size = n_people, replace = TRUE) #draw n_people birthdays, each between 1 and 365
  any(duplicated(birthdays)) # return true if any birthday appears more than once
}
```

```{r group_size_2_to_50}
n_sims = 10000 # number of simulations
birthday_results = 
  tibble(n = 2:50) |>
  mutate(
    # for each n, do 10000 independent simulations
    sim_results = map(
      n, 
      ~ replicate(n_sims, birthday_sim(.x))
    )
  ) |>
  # turn the logical vectors into long format
  unnest_longer(sim_results, values_to = "shared_birthday") |>
  group_by(n) |>
  summarize(
    prob_shared = mean(shared_birthday), # "TRUE" = 1, "FALSE" = 0"
    .groups = "drop"
  )
head(birthday_results)
```

```{r birthday_plot}
birthday_results |>
  ggplot(aes(x = n, y = prob_shared)) + 
  geom_line() + 
  geom_point() + 
  labs(
    x = "Group size(n)", 
    y = "Probability of at least two share a brithday", 
    title = "Probabilty of shared birthday vs group size"
  )
```

#### Comment
- When the group sizes are small, the probability of two shared the same birthday is close to 0. 

- The probability increases as n increases, and is above 0.5 when n is approx. 23. 

- For relatively larger groups (close to 50), the probability of shared birthday approaches 1, indicating it is extremely likely that at least two people share a birthday. 

### Problem 2
#### Simulation result
```{r sim_result}
set.seed(12345)
# function that runs simulations for a given true mean "mu_true"

n = 30
sigma = 5
mu_true = 0
mu_values = 0:6
n_sims = 5000

sim_results = expand_grid(
  mu = mu_values, 
  sim = 1:5000
) |>
  mutate(
    # for each row (mu, sim) generate data from N(mu, sigma)
    x = map(mu, ~rnorm(n = n, mean = .x, sd = sigma)), 
    # one sample t-test of H0: mu = 0
    t_out = map(x, ~t.test(.x, mu = 0)), 
    # tidy the output
    t_tidy = map(t_out, broom::tidy)
  ) |>
  unnest(t_tidy) |>
  select(mu, sim, estimate, p.value)
```

#### Power result
```{r power_result}
power_results = 
  sim_results |>
  group_by(mu) |> # group all 5000 simulations by the true mu
  summarise(
    power = mean(p.value < 0.05), # compute the proportion of p-values that are < 0.05
    .groups = "drop" 
  )

power_results |>
  knitr::kable(
    caption = "Power Estimates for Each True Mean (mu)", 
    digits = 3, 
    align = "c"
  )
```

```{r power_vs_mu_plot}
ggplot(power_results, aes(x = mu, y = power)) +
  geom_line() + # connect points with line
  geom_point() +
  labs(
    x = "True mean (mu)",
    y = "Estimated power",
    title = "Power of One Sample t-test vs True Mean (mu)"
  ) +
  ylim(0, 1) # range, power is between 0 and 1
```

#### mu-hat Result
```{r mu_hat_results}
mu_hat_results =
  sim_results |>
  group_by(mu) |> # group by true mean
  summarize(
    avg_estimate_all = mean(estimate), # calculate the avg sample mean across all simulations
    avg_estimate_reject = mean(estimate[p.value < 0.05]), # calculate the avg sample mean only when H0 rejected (ie. p<0.05)
    .groups = "drop"
  )

mu_hat_long = # convert to long format
  mu_hat_results |>
  pivot_longer(
    cols = c(avg_estimate_all, avg_estimate_reject),
    names_to = "estimate_type",
    values_to = "mean_estimate"
  ) |>
  mutate(
    estimate_type = case_when(
      estimate_type == "avg_estimate_all" ~ "All samples", 
      estimate_type == "avg_estimate_reject" ~ "Only rejected"
    )
  )


```

#### Average estimate of mu-hat vs true mu plot
```{r mu-hat_vs_true_mu_plot}
ggplot(
  mu_hat_long, 
       aes(x = mu, 
           y = mean_estimate, 
           color = estimate_type)
  ) +
  geom_line() +
  geom_point() +
  labs(
    x = "True mean (mu)",
    y = "Average estimate (mu-hat)",
    color = "Estimate Type",
    title = "Average Estimate of mu-hat vs true mu"
  )

knitr::kable(mu_hat_results)
```

Is the sample average of ðœ‡Ì‚ across tests for which the null is rejected approximately equal to the true value of ðœ‡? Why or why not?

- No. The sample avg of ðœ‡Ì‚ among simulations where H0 is rejected does not approx. equal to the true value of mu due to selection bias.
- When power is low (true mu is small), only samples with unusually large mu-hat lead to rejection of H0. So, the conditional mean is biased upward. 
- As mu increases and power approaches 1, nearly all samples reject, so the bias decreases and the conditional mean appraoches the true mu. 

### Problem 3
```{r read dataset}
homicides_raw = 
  read_csv("homicide-data.csv")
```

#### Description of dataset
The raw dataset contains one row per homicide case. There are `r nrow(homicides_raw)` observations, and `r ncol(homicides_raw)` variables.

Important variables include: 
- `uid`: case ID
- `reported_date`: date the homicide was reported
- `city`, `state`: location of the homicide
- `victim_last`,`victim_first`, `victim_race`, `victim_age`, `victim_sex`: demographic information of the victim
- `disposition`: case status

#### Homicides by city_state
```{r homicide by city_state}
homicides_city = 
  homicides_raw |>
  # create city_state variable
  mutate(
    city_state = str_c(city, ",", state), 
    # indicator for unsolved cases ("closed without arrest" or "open/no arrest")
    unsolved = if_else(
      disposition %in% c("Closed without arrest", "Open/No arrest"), 
      1, # unsolved
      0, # solved
    )
  ) |>
  group_by(city_state) |>
  summarize(
    n_homicides = n(), # total number of homicides in city
    n_unsolved = sum(unsolved), # number of unsolved homicides
  )

knitr::kable(homicides_city)
```

#### Unsolved homicides in Baltimore, MD
```{r homicides in Baltimore,MD}
baltimore = homicides_city |>
  filter(city_state == "Baltimore,MD")
baltimore

# run prop.test for Baltimore
baltimore_prop = 
  prop.test(
    x = baltimore$n_unsolved, # number of unsolved cases
    n = baltimore$n_homicides # total number of cases
  )

# tidy the output
baltimore_tidy = 
  baltimore_prop |>
  broom::tidy()

# extract estimated prop. and CI
baltimore_estimate = 
  baltimore_tidy |>
  select(estimate, conf.low, conf.high)

knitr::kable(baltimore_estimate)
```

The estimated proportion of homicides that are unsolved in Baltimore,MD is `r baltimore_estimate$estimate`. 

The 95% confidence interval is (`r baltimore_estimate$conf.low`, `r baltimore_estimate$conf.high`)

#### Proportion of unsolved homicides in all cities
```{r prop test for all cities}
city_prop_results = 
  homicides_city |>
  mutate(
    # list col of prop.test objects
    prop_test = map2(
      n_unsolved, 
      n_homicides, 
      ~ prop.test(x = .x, n = .y)
    ), 
    # list col of tidy data frames
    prop_tidy = map(prop_test, broom::tidy)
  ) |>
  unnest(prop_tidy) |>
  select(
    city_state, 
    n_homicides, 
    n_unsolved, 
    estimate, 
    conf.low, 
    conf.high
  )

knitr::kable(city_prop_results)
```

#### Proportion of unsolved homicides plot
```{r prop. plot by city}
city_prop_results |>
  # organize cities according to the proportion of unsolved homicides
  mutate(
    city_state = fct_reorder(city_state, estimate)
  ) |>
  ggplot(
    aes(x = estimate, 
        y = city_state)
    ) + 
      geom_point() + 
      # add errorbar based on 95% CI
      geom_errorbar(
        aes(xmin = conf.low, 
            xmax = conf.high), 
        width = 0
    )+ 
      labs(
        title = "Estimated Proportion of Unsolved Homicides by City", 
        x = "Estimated proportion unsolved (95% CI)", 
        y = "City"
      ) 
```






